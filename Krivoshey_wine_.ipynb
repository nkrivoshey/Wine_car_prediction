{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "#\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "#\n",
    "# \n",
    "# использую это во 2 блоке, поэтому может необязательно для скачивания\n",
    "#!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline , make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler , Normalizer , PowerTransformer , QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,HalvingGridSearchCV, KFold \n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit, StratifiedShuffleSplit , LeaveOneOut\n",
    "from sklearn.metrics import r2_score , accuracy_score, precision_score, recall_score ,log_loss,balanced_accuracy_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import RocCurveDisplay, DetCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (поиск лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Данный блок(и) НЕ выполняются преподавателем в области 2\n",
    "# блок(и) предназначены для поиска лучшей модели\n",
    "# \n",
    "# Запрещается размещать данные блоки за пределами обасти 2\n",
    "# Все блоки данной области должны быть выполнены\n",
    "#\n",
    "# Путь к тренировочному набору\n",
    "# \n",
    "\n",
    "path_train = 'wine_train.csv' # содержит только имя файла, без имен папок !\n",
    "df_raw = pd.read_csv(path_train)\n",
    "\n",
    "# меняем качества вин, где 7 и более -  1, обратное - 0\n",
    "df_raw['quality'] = np.where(df_raw['quality'] >= 7 , 1 , 0)\n",
    "display(df_raw)\n",
    "\n",
    "# ПОЧИСТИМ НАШИ ДАННЫЕ\n",
    "\n",
    "#нулевые значения в данных(проверял на всех и нашел только в этом столбце)\n",
    "#убеждаемся, что есть дубликаты и нужно будет их отчистить\n",
    "\n",
    "#df_row.duplicated().sum() дубликатов - 560--- нужно их удалить\n",
    "\n",
    "temp = df_raw.drop_duplicates(keep = 'last',ignore_index= True) # сначала дропаем дубликаты\n",
    "oshibki = temp[temp['citric acid'] == 0.000].index # находим индексы где у нас есть 0 , можно будет убрать их\n",
    "# подготовленный фрейм для работы\n",
    "df = temp.drop(index = oshibki).reset_index(drop = True)#[coll]\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно посмотреть на наши данные \n",
    "for i in df.columns:\n",
    "    sns.histplot(df_raw[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверить, что нет дубликатов\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводка данных по фреймам\n",
    "#otchet = df_raw.profile_report()\n",
    "otchet1 = df.profile_report()\n",
    "display(otchet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#можно глянуть на тепловую карту\n",
    "correlation_matrix = df.corr()\n",
    "# Выводим признаки на тепловую карту\n",
    "plt.figure(figsize= (10, 6))\n",
    "sns.heatmap(correlation_matrix, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# блок для простого анализа\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =0.3, random_state=42)\n",
    "\n",
    "scaler = RobustScaler() \n",
    "scaler.fit(X_train)     \n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)   \n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "sc_train = knn.score(X_train_scaled , y_train)\n",
    "sc_test =  knn.score(X_test_scaled ,  y_test)\n",
    "\n",
    "print(\"тренировочный: {:.3f}\".format(sc_train))\n",
    "print(\"тестовый: {:.3f}\".format(sc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), \n",
    "    ('regressor',    KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "#cv = KFold()\n",
    "#cv = ShuffleSplit(n_splits = 10,shuffle=True)\n",
    "cv = KFold(n_splits= 15, shuffle= True) \n",
    "#cv = StratifiedShuffleSplit(n_splits = 15)\n",
    "#cv = LeaveOneOut()\n",
    "#cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Определим параметры для перебора по решетке\n",
    "p = np.arange(1,6)            \n",
    "n_neighbors = np.arange(1,16)\n",
    "weights = ['uniform','distance']\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(),Normalizer()]\n",
    "\n",
    "param_grid = [ \n",
    "    {'preprocessing':scaling,\n",
    "     'regressor': [KNeighborsClassifier()],\n",
    "     'regressor__p':p,\n",
    "     'regressor__n_neighbors': n_neighbors,\n",
    "     'regressor__weights': weights}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv, return_train_score=True, n_jobs=-1, scoring= 'accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =.25, random_state = 42)\n",
    "\n",
    "\n",
    "finish_pipe1 =  Pipeline([\n",
    "            ('preprocessing', RobustScaler()), \n",
    "            ('regressor',     KNeighborsClassifier(n_neighbors = 13, p = 4, weights = 'distance'))\n",
    "            ])\n",
    "finish_pipe1.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe1.score(X_train,y_train))\n",
    "print(finish_pipe1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =.3, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', RobustScaler()), \n",
    "                 ('clf',           LogisticRegression(max_iter=3000))])\n",
    "\n",
    "# n_splits = 5, random_state = 42 дают не улачную комбинацию и это хорошо для разбора ошибок решетки\n",
    "\n",
    "#cv = StratifiedShuffleSplit(n_splits = 10)\n",
    "#cv = ShuffleSplit(n_splits = 25)\n",
    "#cv = LeaveOneOut()\n",
    "cv = KFold(n_splits= 20, shuffle= True)\n",
    "\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(), Normalizer(), PowerTransformer(), QuantileTransformer()]\n",
    "\n",
    "param_grid =[\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l2'], \n",
    "         'clf__solver': ['newton-cg' ,'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l1'], \n",
    "         'clf__solver': ['liblinear']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['none'], \n",
    "         'clf__solver': ['lbfgs','newton-cg']}\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = cv, return_train_score = True, scoring= 'accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подставляем параметры в контейнер\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =.3, random_state = 42)\n",
    "\n",
    "finish_pipe2 =  make_pipeline(QuantileTransformer(), LogisticRegression(solver = 'liblinear', penalty = 'l2', max_iter=4500) )\n",
    "finish_pipe2.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe2.score(X_train,y_train))\n",
    "print(finish_pipe2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну тут можно подкрутить \"С\", но если penalty != none\n",
    "# можно подкрутить модель\n",
    "pipe_fin = make_pipeline(QuantileTransformer(), LogisticRegression(solver = 'liblinear', penalty = 'l2', max_iter=4500))\n",
    "\n",
    "\n",
    "n_range = np.linspace(0.0001, 6, 500)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    pipe_fin , X_train, y_train,\n",
    "    param_name = \"logisticregression__C\", \n",
    "    param_range = n_range,\n",
    "    cv = cv, \n",
    "    scoring= \"accuracy\", \n",
    "    n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"сила регуляризации\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.7, 1.05)\n",
    "\n",
    "plt.plot(n_range, train_scores_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.fill_between(n_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\")\n",
    "plt.plot(n_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.fill_between(n_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\")\n",
    "\n",
    "plt.xticks(np.linspace(0, 6, 15))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_end = make_pipeline(QuantileTransformer(), LogisticRegression(solver = 'liblinear', penalty = 'l2', max_iter=4500, C=0.4))\n",
    "pipe_end.fit(X_train,y_train)\n",
    "print(pipe_end.score(X_train,y_train))\n",
    "print(pipe_end.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гаус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', RobustScaler()), \n",
    "                 ('clf',           GaussianNB())])\n",
    "\n",
    "#cv = StratifiedShuffleSplit(n_splits = 20)\n",
    "#cv = ShuffleSplit(n_splits = 20)\n",
    "cv = KFold(n_splits= 20, shuffle= True)\n",
    "\n",
    "scaling = [ MinMaxScaler(), StandardScaler(), RobustScaler(), Normalizer(), PowerTransformer(), QuantileTransformer()]\n",
    "\n",
    "param_grid =[\n",
    "    {'preprocessing': scaling, \n",
    "     'clf': [GaussianNB()]}\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = cv, return_train_score = True, scoring= 'accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =0.25, random_state=42)\n",
    "\n",
    "finish_pipe3 = Pipeline(steps=[('preprocessing', PowerTransformer()), ('clf', GaussianNB())])\n",
    "finish_pipe3.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe3.score(X_train,y_train))\n",
    "print(finish_pipe3.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =0.3, random_state = 42)\n",
    "\n",
    "\n",
    "model_NB = make_pipeline(PowerTransformer(),GaussianNB())\n",
    "model_LR = make_pipeline(QuantileTransformer(), LogisticRegression(solver = 'liblinear', penalty = 'l2', max_iter=4500, C=0.4))\n",
    "model_KNN = make_pipeline(RobustScaler(), KNeighborsClassifier(n_neighbors = 13, p = 4, weights = 'distance'))\n",
    "\n",
    "\n",
    "model_NB.fit(X_train,y_train)\n",
    "model_LR.fit(X_train,y_train)\n",
    "model_KNN.fit(X_train,y_train)\n",
    "\n",
    "y_NB_pred = model_NB.predict(X_test)\n",
    "y_LR_pred = model_LR.predict(X_test)\n",
    "y_KNN_pred = model_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.DataFrame(classification_report(y_test, y_NB_pred, output_dict=True)).T\n",
    "df2 = pd.DataFrame(classification_report(y_test, y_LR_pred, output_dict=True)).T\n",
    "df3 = pd.DataFrame(classification_report(y_test, y_KNN_pred, output_dict=True)).T\n",
    "\n",
    "df1_styler = df1.style.set_table_attributes(\"style='display:inline'\").set_caption('GaussianNB')\n",
    "df2_styler = df2.style.set_table_attributes(\"style='display:inline'\").set_caption('LogisticRegression')\n",
    "df3_styler = df3.style.set_table_attributes(\"style='display:inline'\").set_caption('KNN')\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_()+df3_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_pipe1.fit(X_train,y_train)\n",
    "finish_pipe2.fit(X_train,y_train)\n",
    "finish_pipe3.fit(X_train,y_train)\n",
    "\n",
    "y_pred_1 = finish_pipe1.predict(X_test)\n",
    "y_pred_2 = finish_pipe2.predict(X_test)\n",
    "y_pred_3 = finish_pipe3.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "matrix_1=confusion_matrix(y_test,y_pred_1)\n",
    "matrix_2=confusion_matrix(y_test,y_pred_2)\n",
    "matrix_3=confusion_matrix(y_test,y_pred_2)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(15,5))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "sns.heatmap(matrix_1,annot=True, fmt='g', cbar=None,cmap=\"Blues\");\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "sns.heatmap(matrix_2,annot=True, fmt='g', cbar=None,cmap=\"Blues\");\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "sns.heatmap(matrix_3,annot=True, fmt='g', cbar=None,cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_roc = plt.subplots(1,1, figsize=(10, 5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_roc, name = 'pipe_1');\n",
    "RocCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_roc, name = 'pipe_2');\n",
    "RocCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_roc, name = 'pipe_3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax_roc, ax_det] = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_roc, name = 'pipe_1');\n",
    "RocCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_roc, name = 'pipe_2');\n",
    "RocCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_roc, name = 'pipe_3');\n",
    "\n",
    "DetCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_det, name = 'pipe_1');\n",
    "DetCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_det, name = 'pipe_2');\n",
    "DetCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_det, name = 'pipe_3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 3 (выполнение лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) в области 3 выполняется преподавателем\n",
    "#\n",
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Путь к тренировочному набору\n",
    "path_train = 'wine_train.csv' # содержит только имя файла, без имен папок\n",
    "df_raw = pd.read_csv(path_train)\n",
    "df_raw['quality'] = np.where(df_raw['quality'] >= 7 , 1 , 0)\n",
    "temp = df_raw.drop_duplicates(keep = 'last',ignore_index= True) # сначала дропаем дубликаты\n",
    "# 0 значения есть только здесь(заранее заметил это)\n",
    "oshibki = temp[temp['citric acid'] == 0.000].index # находим индексы где у нас есть 0 , можно будет убрать их\n",
    "df = temp.drop(index = oshibki).reset_index(drop = True)\n",
    "#display(df)\n",
    "\n",
    "# Путь к тестовому набору\n",
    "path_test  = 'wine_test.csv' # содержит только имя файла, без имен папок\n",
    "df1_raw = pd.read_csv(path_test)\n",
    "ind_duble = df1_raw[df1_raw.duplicated(keep = 'last') == True].index\n",
    "df2_raw = df1_raw.drop(index = ind_duble).reset_index(drop = True)\n",
    "oshibki1 = df2_raw[df2_raw['citric acid'] == 0.000].index # ошибка была тут-я индексы ошибок брал с df1_raw\n",
    "df1 = df2_raw.drop(index = oshibki1).reset_index(drop = True) # а нужно было с обрезанного, а не изначального\n",
    "display(df1)                                                  \n",
    "\n",
    "#я тут неправильно переобозначил фреймы, если посмотреть изначальный файл - теперь исправил\n",
    "# нужно было всего написать цифру или по другому фрейм назвать в 3 местах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок(и) обучения и поверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['quality'],axis = 1), df['quality'], test_size =.3)\n",
    "\n",
    "\n",
    "finish_pipe =  Pipeline([\n",
    "            ('preprocessing', RobustScaler()), \n",
    "            ('regressor',     KNeighborsClassifier(n_neighbors = 13, p = 3, weights = 'distance'))\n",
    "            ])\n",
    "finish_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe.score(X_train,y_train))\n",
    "print(finish_pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = finish_pipe.predict(df1)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Название вектора предсказанных значений  y_predict полученого на основании тестового набора\n",
    "y_predict = y_predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подстановка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['quality']\n",
    "# вставить файл с данными в ''\n",
    "y_true_raw = pd.read_csv('.....').[column] \n",
    "y_true_raw['quality'] = np.where(y_true_raw['quality'] >= 7 , 1 , 0)\n",
    "# Срезаем фрейм по удаленным индексам : ind_duble, oshibki1\n",
    "temp1 = y_true_raw.drop(index = ind_duble).reset_index(drop = True)\n",
    "y_true = temp1.drop(index = oshibki1).reset_index(drop = True)\n",
    "# готовый \n",
    "y_true\n",
    "\n",
    "#ошибка в оформелнии к тестовому набору "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
